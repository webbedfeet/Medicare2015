---
title: "Medicare 2015 Notes"
author: "Abhijit Dasgupta"
output: 
  html_notebook:
    highlight: tango
    includes:
      in_header: header.html
    number_sections: no
    theme: journal
---

```{r setup, warning=FALSE, message = FALSE, include = FALSE}
library(tidyverse)
```


# Introduction

This study seeks to understand why rates of primary knee replacements vary across geographical 
regions. There are 306 geographical regions in this study, with the rate of knee replacement varying
from 4/1000 to 14/1000. This study covers the years 2011-2015, for a total of 147M records (about 35M 
patients), with one record per person-year. 

Earlier studies have attempted to look at this data standardized for age, sex, and race, and 
have still found variability in the incidence rates. The tacit assumption that was made in earlier 
studies is that the rate of osteoarthritis (OA) of the knee is uniform across the country. 

The obvious criticism of earlier findings is that there are unmeasured confounders that would account
for the variability. This study attempts to incorporate many of the confounders to see if they can
account for the observed variability adequately. These confounders include comorbidities (affects the
risk of getting a replacement), healthcare utiliization variables (do people differ in going to the
doctor due to differences in access or attitudes), and physician attitudes (captured by % with Medicare
Avantage HMO, which can have spillover attitudinal effects on doctors[^1], and availability of 
orthopedic surgeons).

The most common reason for knee replacement is osteoarthritis (OA) of the knee, which is a repeated
use degenerative disorder, so the incidence of OA can be related to occupation. This should be 
captured in the `physjob_t_wtperc` variable at least at the region level.

# Data
The individual level identifier is `bene_id`. There are 20 comorbidities captured each year of a patient's
participation in the study. Person-years exposed is captured in the `Personyrs` variable. 

+ Region ids `hrr` have 306 unique values, but are not sequential
+ Once a patient reaches 2 replacements (either 1+1 or 2), they should have 0 replacements in the 
following years, since we're only looking at primary replacements and not revisions. 
+ `poor` is defined as also being on Medicaid

# Code

### Subsetting data

We'll start developing models on a subset of the data, say on 1M subjects. This is to ensure that
we can iterate on code quickly without waiting 2 days for code to run. To do this, Mike suggests using
`PROC SURVEYSELECT`

```sas
proc surveyselect data=sh026544.project4_hrr_end15 out=sh026544.project4_hrr_end15_sampled 
    noprint method=srs sampsize = 1000000 seed=3589;
  cluster bene_id;
  run;
```
It turns out this code breaks due to "insufficient memory". I figured out a more efficient way
using `PROC SQL`:

```sas
proc sql noprint;
  create table sh026544.tmp_id as 
    select distinct bene_id from sh0256544.project4_hrr_end15;

proc surveyselect data=sh026544.tmp_id out = sh026544.tmp_sampled_id method = srs seed=745278 sampsize=500000 noprint;
run;

proc sql noprint;
  create table sh026544.proj4_hrr_end15_sample as
    select A.*, B.* from
      sh026544.tmp_sampled_id A left join sh026544.project4_hrr_end15 B
        on A.bene_id=B.bene_id
          order by bene_id, bene_enrollmt_ref_yr;
```

### Analysis

~~I feel that the outcome measure is really distributed as Bin(2,p), rather than a Poisson. In fact,~~ 
~~theory would suggest that the Poisson would not be a good approximation to the Binomial in this case,~~
~~so I'd be reluctant to use a Poisson model on this.~~

Empirically, the rates of getting knee replacements range from 0.04 to 0.14. If we keep this range
of rates, and do a quick simulation based on a logistic model, we see that the Poisson approximation 
works quite well, specially with regards to the predicted values (i.e., the rate $\lambda$ of getting a 
replacement as compared to the probability of not getting a replacement; 
$$ 1-p(x) \equiv \exp (-\lambda (x))$$

```{r}
set.seed(201205)
X = matrix(rbinom( 10000*10, 1, 0.2), ncol=10)
X = cbind(V0 = 1, X)
beta = matrix(rnorm(11), ncol=1)
beta[1] = -3
linpred = X%*%beta
Y = rbinom(10000, 1, plogis(linpred))
d = as.data.frame(X)
d$Y = Y
d = select(d, -V0)
m1 = glm(Y~., data = d, family = binomial)
m2 = glm(Y~., data=d, family = poisson)

p1 <- predict(m1, type = 'response') # p
l <- predict(m2, type = 'response') # lambda
d <- tibble(p1, l)
plt <- ggplot(d, aes(1-p1,exp(-l)))+geom_point()+geom_abline()+
  labs(x='P(Y=0) under logistic', y = 'P(Y=0) under Poisson')
print(plt)
```

Even if we model the outcomes as a true Binomial where outcomes can be 0, 1, or 2, the Poisson model actually
gets the predictions pretty well. 

```{r, out.width='75%'}
set.seed(201205)
X = matrix(rbinom( 10000*10, 1, 0.2), ncol = 10)
X = cbind(V0 = 1, X)
beta = matrix(rnorm(11), ncol = 1)
beta[1] = -3
linpred = X %*% beta
Y = rbinom(10000, 2, plogis(linpred))
d = as.data.frame(X)
d$Y = Y
d = select(d, -V0)
m1 = glm(Y/2~., data = d, family = binomial, weights = rep(2, nrow(d)))
m2 = glm(Y~., data = d, family = poisson)

p1 <- predict(m1, type = 'response') # p
l <- predict(m2, type = 'response') # lambda
d <- tibble(p1, l)
ggplot(d, aes((1-p1)^2,exp(-l)))+geom_point() + geom_abline() + 
  labs(x = 'P(Y=0) under logistic', y = 'P(Y=0) under Poisson')

```


~~I've been thinking that a better first analysis is to look at the rate of primary replacement with covariates. This can avoid the issue having correlated binary outcomes without sufficient information to analyze it. A potential twist would be to include a covariate whether other leg was already replaced, which would be a modifier for the risk of replacement. If bilateral replacement happens, it is still just counted once as a replacement event; a secondary analysis can be done whether bilateral replacements are more likely under certain person/environment combinations.~~

The workhorse for this analysis will be `PROC GLIMMIX`, or potentially `PROC GENMOD` if we go towards
GEE analysis. However, for having multilevel covariates, `GLIMMIX` might be the better option. 
GLIMMIX will allow for the multilevel modeling using nested random effects, under either a Poisson or 
negative binomial model. The ultimate goal is to use this to find the predicted rate of knee replacements
by region under this model, and how much that varies across regions. This should show up as a 
variance component in the model, or a combination of variance components. 

## Models

### Poisson regression

See [link1](http://www.misug.org/uploads/8/1/9/1/8191072/kwelch_clustered_longitudinal_analysis.pdf) and
[link2](https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_glimmix_sect026.htm)

The general framework of this model is:

```sas
proc glimmix data = sh026544.project4_hrr_end15 method = quad;
  
  class year bene_id hrr ... ;
  model y = ... / link = log s dist = poisson offset = lexposure;
  random hrr;
  random int / subject = bene_id(hrr);
```

#### Model 1: Age, sex and race

We would like to fit a model that captures the nonlinear effect of age using splines, rather than 
using categorical variables. 

> Information about splines in SAS are [here](http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_introcom_sect020.htm)
>

High memory tricks are [here](http://support.sas.com/kb/37/047.html)
Resources: [link](http://www.okstate.edu/sas/v8/sashtml/os2/zatalibs.htm), 
```sas
data sh026544.project4_hrr_end15_small;
  set sh026544.project4_hrr_end15_small;
  ltime = log(personyrs);
  run;
proc glimmix data = sh026544.project4_hrr_end15_small;
  class Male Race;
  effect age_spl = spline(Age_at_end_ref_yr);
  model Tka = age_spl|Male|Race@2 / dist = poisson solution offset = ltime ;
  random hrr/ solution;
  random  intercept/ solution subject = bene_id(hrr);
  output out = mod1_out pred = p1_pred;
  run;
```




[^1]: Doctors who have a lot of patients in Medicare Advantange, which is a managed care HMO, tend to
be influenced by that culture which promotes lower cost treatments. This attitude often can spill over
to the fee-for-service general Medicare population, which would then tend to get more conservative,
lower cost treatment. 
